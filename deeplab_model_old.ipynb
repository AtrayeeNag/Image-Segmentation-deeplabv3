{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabV3+_refactor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKV5qu5nDgVl",
        "colab_type": "code",
        "outputId": "842051db-ee25-4309-fa21-7270c2dc3397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.activations import relu\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.python.keras.layers import Activation\n",
        "from tensorflow.python.keras.layers import Add, Reshape\n",
        "from tensorflow.python.keras.layers import BatchNormalization\n",
        "from tensorflow.python.keras.layers import Concatenate\n",
        "from tensorflow.python.keras.layers import Conv2D\n",
        "from tensorflow.python.keras.layers import DepthwiseConv2D\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "from tensorflow.python.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.python.keras.layers import Input\n",
        "from tensorflow.python.keras.layers import Lambda\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import ZeroPadding2D\n",
        "from tensorflow.python.keras.utils.layer_utils import get_source_inputs\n",
        "from tensorflow.python.keras.utils.data_utils import get_file"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_P-IGqBIjEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WEIGHTS_PATH_X = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\"\n",
        "WEIGHTS_PATH_MOBILE = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5\"\n",
        "WEIGHTS_PATH_X_CS = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.2/deeplabv3_xception_tf_dim_ordering_tf_kernels_cityscapes.h5\"\n",
        "WEIGHTS_PATH_MOBILE_CS = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.2/deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels_cityscapes.h5\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm32Rfum-v8F",
        "colab_type": "code",
        "outputId": "b4ce8dc7-a030-4707-92e9-dd595b80b889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_JsS1UTgdol",
        "colab_type": "text"
      },
      "source": [
        "## Create the DeeplabV3+ Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUZX-1CFgirv",
        "colab_type": "text"
      },
      "source": [
        "### Change image padding for different strides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gal-ouYxpT8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def changePadding(x, stride, kernel_size, rate):\n",
        "  if stride == 1:\n",
        "      depth_padding = 'same'\n",
        "  else:\n",
        "      kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
        "      pad_total = kernel_size_effective - 1\n",
        "      pad_beg = pad_total // 2\n",
        "      pad_end = pad_total - pad_beg\n",
        "      x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
        "      depth_padding = 'valid'\n",
        "  return x, depth_padding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ky_Fjv8hIw8",
        "colab_type": "text"
      },
      "source": [
        "### Depthwise Separable Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOsVHEBrFXLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SepConv(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n",
        "\n",
        "    if stride == 1:\n",
        "        depth_padding = 'same'\n",
        "    else:\n",
        "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
        "        pad_total = kernel_size_effective - 1\n",
        "        pad_beg = pad_total // 2\n",
        "        pad_end = pad_total - pad_beg\n",
        "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
        "        depth_padding = 'valid'\n",
        "\n",
        "    if not depth_activation:\n",
        "        x = Activation('relu')(x)\n",
        "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n",
        "                        padding=depth_padding, use_bias=False, name=prefix + '_depthwise')(x)\n",
        "    x = BatchNormalization(name=prefix + '_depthwise_BN', epsilon=epsilon)(x)\n",
        "    if depth_activation:\n",
        "        x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, (1, 1), padding='same',\n",
        "               use_bias=False, name=prefix + '_pointwise')(x)\n",
        "    x = BatchNormalization(name=prefix + '_pointwise_BN', epsilon=epsilon)(x)\n",
        "    if depth_activation:\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCGxdNoQjLo5",
        "colab_type": "text"
      },
      "source": [
        "### Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcKXdRxTIhGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xception_model(img_input):\n",
        "\n",
        "    x_conv1 = Conv2D(32, (3, 3), strides=(2, 2), name='entry_flow_conv1_1', use_bias=False, padding='same', dilation_rate=(1, 1))(img_input)\n",
        "    x_conv1 = BatchNormalization(name='entry_flow_conv1_1_BN')(x_conv1)\n",
        "    x_conv1 = Activation('relu')(x_conv1)\n",
        "\n",
        "    x_conv1 = Conv2D(64, (3, 3), strides=(1, 1), use_bias=False, padding='same', name ='entry_flow_conv1_2', dilation_rate=(1, 1))(x_conv1)\n",
        "    x_conv1 = BatchNormalization(name='entry_flow_conv1_2_BN')(x_conv1)\n",
        "    x_conv1 = Activation('relu')(x_conv1)\n",
        "\n",
        "    x_conv_str, depth_padding = changePadding(x_conv1, 2, 1, 1)\n",
        "    x_conv_str = Conv2D(128, (1, 1), strides=(2, 2), use_bias=False, padding='valid', name='entry_flow_block1_shortcut', dilation_rate=(1, 1))(x_conv_str)\n",
        "\n",
        "    x_sep1 = SepConv(x_conv1, 128, 'entry_flow_block1_separable_conv{}'.format(1), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep1 = SepConv(x_sep1, 128, 'entry_flow_block1_separable_conv{}'.format(2), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep1 = SepConv(x_sep1, 128, 'entry_flow_block1_separable_conv{}'.format(3), stride=2, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "\n",
        "    x_conv2 = layers.add([x_sep1, x_conv_str])\n",
        "   \n",
        "    x_conv_str, depth_padding = changePadding(x_conv2, 2, 1, 1)\n",
        "    x_conv_str = Conv2D(256, (1, 1), strides=(2, 2), use_bias=False, padding='valid', name = 'entry_flow_block2_shortcut', dilation_rate=(1, 1))(x_conv_str)\n",
        "    x_conv_str = BatchNormalization(name='entry_flow_block2_shortcut_BN')(x_conv_str)\n",
        "\n",
        "    x_sep2 = SepConv(x_conv2, 256, 'entry_flow_block2_separable_conv{}'.format(1), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep2 = SepConv(x_sep2, 256, 'entry_flow_block2_separable_conv{}'.format(2), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    skip1 = x_sep2\n",
        "    x_sep2 = SepConv(x_sep2, 256, 'entry_flow_block2_separable_conv{}'.format(3), stride=2, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "\n",
        "    x_conv3 = layers.add([x_sep2, x_conv_str])\n",
        "    \n",
        "    x_conv_str, depth_padding = changePadding(x_conv3, 2, 1, 1)\n",
        "    x_conv_str = Conv2D(728, (1, 1), strides=(2, 2), use_bias=False, padding='valid', name = 'entry_flow_block3_shortcut', dilation_rate=(1, 1))(x_conv_str)\n",
        "    x_conv_str = BatchNormalization(name='entry_flow_block3_shortcut_BN')(x_conv_str)\n",
        "\n",
        "    x_sep3 = SepConv(x_conv3, 728, 'entry_flow_block3_separable_conv{}'.format(1), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep3 = SepConv(x_sep3, 728, 'entry_flow_block3_separable_conv{}'.format(2), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep3 = SepConv(x_sep3, 728, 'entry_flow_block3_separable_conv{}'.format(3), stride=2, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    \n",
        "    x_conv4 = layers.add([x_sep3, x_conv_str])\n",
        "\n",
        "    for i in range(16):\n",
        "      x_sep4 = SepConv(x_conv4, 728, 'middle_flow_unit_{}'.format(i + 1)+'_separable_conv{}'.format(1), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "      x_sep4 = SepConv(x_sep4, 728, 'middle_flow_unit_{}'.format(i + 1)+'_separable_conv{}'.format(2), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "      x_sep4 = SepConv(x_sep4, 728, 'middle_flow_unit_{}'.format(i + 1)+'_separable_conv{}'.format(3), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "      x_conv4 = layers.add([x_sep4, x_conv4])\n",
        "\n",
        "    x_conv_str = Conv2D(1024, (1, 1), strides=(1, 1), use_bias=False, padding='same', name = 'exit_flow_block1_shortcut', dilation_rate=(1, 1))(x_conv4)\n",
        "    x_conv_str = BatchNormalization(name='exit_flow_block1_shortcut_BN')(x_conv_str)\n",
        "\n",
        "    x_sep5 = SepConv(x_conv4, 728, 'exit_flow_block1_separable_conv{}'.format(1), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep5 = SepConv(x_sep5, 1024, 'exit_flow_block1_separable_conv{}'.format(2), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "    x_sep5 = SepConv(x_sep5, 1024, 'exit_flow_block1_separable_conv{}'.format(3), stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3)\n",
        "\n",
        "    x_conv5 = layers.add([x_sep5, x_conv_str])\n",
        "\n",
        "    x_sep6 = SepConv(x_conv5, 1536, 'exit_flow_block2_separable_conv{}'.format(1), stride=1, kernel_size=3, rate=2, depth_activation=True, epsilon=1e-3)\n",
        "    x_sep6 = SepConv(x_sep6, 1536, 'exit_flow_block2_separable_conv{}'.format(2), stride=1, kernel_size=3, rate=2, depth_activation=True, epsilon=1e-3)\n",
        "    x_sep6 = SepConv(x_sep6, 2048, 'exit_flow_block2_separable_conv{}'.format(3), stride=1, kernel_size=3, rate=2, depth_activation=True, epsilon=1e-3)\n",
        "\n",
        "    return x_sep6, skip1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CIfubMtjVyA",
        "colab_type": "text"
      },
      "source": [
        "### Atrous Spatial Pyramid Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBnR5U1YGK-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aspp(input):\n",
        "    \n",
        "    x = input\n",
        "    atrous_rates = (6, 12, 18)\n",
        "    shape_before = tf.shape(x)\n",
        "\n",
        "    b4 = GlobalAveragePooling2D()(x)\n",
        "    b4 = Lambda(lambda x: K.expand_dims(x, 1))(b4)\n",
        "    b4 = Lambda(lambda x: K.expand_dims(x, 1))(b4)\n",
        "    b4 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='image_pooling')(b4)\n",
        "    b4 = BatchNormalization(name='image_pooling_BN', epsilon=1e-5)(b4)\n",
        "    b4 = Activation('relu')(b4)\n",
        "    \n",
        "    size_before = tf.keras.backend.int_shape(x)\n",
        "    b4 = Lambda(lambda x: tf.compat.v1.image.resize(x, size_before[1:3], method='bilinear', align_corners=True))(b4)\n",
        "  \n",
        "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n",
        "    b0 = BatchNormalization(name='aspp0_BN', epsilon=1e-5)(b0)\n",
        "    b0 = Activation('relu', name='aspp0_activation')(b0)\n",
        "\n",
        "    b1 = SepConv(x, 256, 'aspp1', rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n",
        "    b2 = SepConv(x, 256, 'aspp2', rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n",
        "    b3 = SepConv(x, 256, 'aspp3', rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n",
        "\n",
        "    x = Concatenate()([b4, b0, b1, b2, b3])\n",
        "    return x;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRlaThWrjovy",
        "colab_type": "text"
      },
      "source": [
        "### Decoder Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YjphlftpJgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decoder(img_input, x, skip1, classes):\n",
        "\n",
        "    x = Lambda(lambda xx: tf.compat.v1.image.resize(xx, skip1.shape[1:3], method='bilinear', align_corners=True))(x)\n",
        "\n",
        "    dec_skip1 = Conv2D(48, (1, 1), padding='same', use_bias=False, name='feature_projection0')(skip1)\n",
        "    dec_skip1 = BatchNormalization(name='feature_projection0_BN', epsilon=1e-5)(dec_skip1)\n",
        "    dec_skip1 = Activation('relu')(dec_skip1)\n",
        "\n",
        "    x = Concatenate()([x, dec_skip1])\n",
        "    x = SepConv(x, 256, 'decoder_conv0', depth_activation=True, epsilon=1e-5)\n",
        "    x = SepConv(x, 256, 'decoder_conv1', depth_activation=True, epsilon=1e-5)\n",
        "\n",
        "    x = Conv2D(classes, (1, 1), padding='same', name='logits_semantic')(x)\n",
        "\n",
        "    size_before3 = tf.keras.backend.int_shape(img_input)\n",
        "    x = Lambda(lambda xx: tf.compat.v1.image.resize(xx, size_before3[1:3], method='bilinear', align_corners=True))(x)\n",
        "    \n",
        "    return x;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm5vfiaDj6Mt",
        "colab_type": "text"
      },
      "source": [
        "### Deeplabv3 Plus Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz_TrTcbLzo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Deeplabv3(weights='pascal_voc', input_shape=(512, 512, 3), classes=21, OS=16):\n",
        "\n",
        "    if not (weights in {'pascal_voc', 'cityscapes', None}):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `pascal_voc`, or `cityscapes` '\n",
        "                         '(pre-trained on PASCAL VOC)')\n",
        "\n",
        "    img_input = Input(shape=input_shape)\n",
        "\n",
        "    x, skip1 = xception_model(img_input)\n",
        "    \n",
        "    x = aspp(x)\n",
        "\n",
        "    x = Conv2D(256, (1, 1), padding='same', use_bias=False, name='concat_projection')(x)\n",
        "    x = BatchNormalization(name='concat_projection_BN', epsilon=1e-5)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    \n",
        "    x = decoder(img_input, x, skip1, classes)\n",
        "\n",
        "    inputs = img_input\n",
        "    print(str(input_shape[0])+','+str(input_shape[1]))\n",
        "    model = Model(inputs, x, name='deeplabv3plus')\n",
        "\n",
        "    weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',\n",
        "                                WEIGHTS_PATH_X,\n",
        "                                cache_subdir='models')\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0DYba9Jza0T",
        "colab_type": "text"
      },
      "source": [
        "##Pre-Process VOC DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ_d-ntc0_oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.data_utils import Sequence\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SegmentationGenerator(Sequence):\n",
        "    \n",
        "    def __init__(self,mode='train', n_classes=21, batch_size=5, resize_shape=None, \n",
        "                 validation_split = .1):\n",
        "        \n",
        "        folder='/gdrive/My Drive/DeepLabV3/VOC2012'\n",
        "        self.image_path_list = []\n",
        "        self.label_path_list = []\n",
        "\n",
        "        image_folder = os.path.join(folder, 'img1')\n",
        "        label_folder = os.path.join(folder, 'lab1')\n",
        "\n",
        "        for(path, dirname, files) in os.walk(label_folder):\n",
        "          for filename in files:\n",
        "            self.label_path_list.append(os.path.join(path, filename))\n",
        "\n",
        "        prefix = len(label_folder)\n",
        "        \n",
        "        for lab_path in self.label_path_list:\n",
        "          self.image_path_list.append(image_folder + lab_path[prefix:-4] + '.jpg')\n",
        "        \n",
        "        n_images_to_select = round(len(self.image_path_list) * validation_split)\n",
        "        x = np.random.permutation(len(self.image_path_list))[:n_images_to_select]\n",
        "            \n",
        "        self.image_path_list = [self.image_path_list[j] for j in x]\n",
        "        self.label_path_list = [self.label_path_list[j] for j in x]\n",
        "\n",
        "        self.mode = mode\n",
        "        self.n_classes = n_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.resize_shape = resize_shape\n",
        "\n",
        "        if self.resize_shape:\n",
        "            self.X = np.zeros((batch_size, resize_shape[1], resize_shape[0], 3), dtype='float32')\n",
        "            self.SW = np.zeros((batch_size, resize_shape[1]*resize_shape[0]), dtype='float32')\n",
        "            self.Y = np.zeros((batch_size, resize_shape[1]*resize_shape[0], 1), dtype='float32')\n",
        "            self.F = np.zeros((batch_size, resize_shape[1]*resize_shape[0], 1), dtype='float32')\n",
        "            self.F_SW = np.zeros((batch_size, resize_shape[1]*resize_shape[0]), dtype='float32')\n",
        "        else:\n",
        "            raise Exception('No image dimensions specified!')\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        for n, (image_path, label_path) in enumerate(zip(self.image_path_list[i*self.batch_size:(i+1)*self.batch_size], \n",
        "                                                        self.label_path_list[i*self.batch_size:(i+1)*self.batch_size])):\n",
        "          \n",
        "            image = cv2.imread(image_path, 1)\n",
        "            label = cv2.imread(label_path, 0)\n",
        "            labels = np.unique(label)\n",
        "\n",
        "            if self.resize_shape:\n",
        "                image = cv2.resize(image, self.resize_shape)\n",
        "                label = cv2.resize(label, self.resize_shape, interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "            label = label.astype('int32')\n",
        "            for j in np.setxor1d(np.unique(label), labels):\n",
        "                label[label==j] = self.n_classes\n",
        "            \n",
        "            y = label.flatten()\n",
        "            y[y>(self.n_classes-1)]=self.n_classes\n",
        "                            \n",
        "            self.Y[n]  = np.expand_dims(y, -1)\n",
        "            self.F[n]  = (self.Y[n]!=0).astype('float32') \n",
        "            valid_pixels = self.F[n][self.Y[n]!=self.n_classes] \n",
        "            u_classes = np.unique(valid_pixels)\n",
        "            class_weights = class_weight.compute_class_weight('balanced', u_classes, valid_pixels)\n",
        "            class_weights = {class_id : w for class_id, w in zip(u_classes, class_weights)}\n",
        "            if len(class_weights)==1:\n",
        "                if 1 in u_classes:\n",
        "                    class_weights[0] = 0.\n",
        "                else:\n",
        "                    class_weights[1] = 0.\n",
        "            elif not len(class_weights):\n",
        "                class_weights[0] = 0.\n",
        "                class_weights[1] = 0.\n",
        "        \n",
        "            sw_valid = np.ones(y.shape)\n",
        "            np.putmask(sw_valid, self.Y[n]==0, class_weights[0]) \n",
        "            np.putmask(sw_valid, self.F[n], class_weights[1]) \n",
        "            np.putmask(sw_valid, self.Y[n]==self.n_classes, 0)\n",
        "            self.F_SW[n] = sw_valid\n",
        "            self.X[n] = image    \n",
        "        \n",
        "            filt_y = y[y!=self.n_classes]\n",
        "            u_classes = np.unique(filt_y)\n",
        "            if len(u_classes):\n",
        "                class_weights = class_weight.compute_class_weight('balanced', u_classes, filt_y)\n",
        "                class_weights = {class_id : w for class_id, w in zip(u_classes, class_weights)}\n",
        "            class_weights[self.n_classes] = 0.\n",
        "            for yy in u_classes:\n",
        "                np.putmask(self.SW[n], y==yy, class_weights[yy])\n",
        "                \n",
        "            np.putmask(self.SW[n], y==self.n_classes, 0)\n",
        "\n",
        "        sample_dict = {'pred_mask' : self.SW}\n",
        "        return self.X, self.Y, sample_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BANDx1Pw0ndq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def create_generators(mode='train', batch_size = 1, do_ahisteq=False, n_classes=21, validation_split=.2):\n",
        "        sz = (512,512)\n",
        "        generator = SegmentationGenerator(mode = mode, n_classes = n_classes, resize_shape=sz[::-1],batch_size= batch_size,\n",
        "                                       validation_split = validation_split)\n",
        "                \n",
        "        return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5WhRc4wz9jM",
        "colab_type": "code",
        "outputId": "e67de2ae-97c4-493a-8cf7-49f1ba75cd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sz = (512,512)\n",
        "deeplab_model = Deeplabv3(weights=None, input_shape=(512,512,3), classes=21, OS=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512,512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2yVlcYzIwY_",
        "colab_type": "text"
      },
      "source": [
        "## Training/Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNkuoLi2LF3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_count = 10\n",
        "valid_generator = create_generators(mode = 'validation', n_classes = 21, validation_split = 1.0, batch_size = 100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gm62vedCFon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "image_batch = []\n",
        "label_batch = []\n",
        "\n",
        "x,y,s = valid_generator.__getitem__(0)\n",
        "\n",
        "image_batch = np.asarray(x)\n",
        "label_batch = np.asarray(y)\n",
        "x_n = (image_batch/ 127.5) - 1.\n",
        "\n",
        "preds1 = np.argmax(deeplab_model.predict(x_n), -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_qDjQQBKDOr",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation Metrics (IOU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9MenlZ0mqyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mIOU(gt, preds):\n",
        "    ulabels = np.unique(gt)\n",
        "    iou = np.zeros(len(ulabels))\n",
        "    for k, u in enumerate(ulabels):\n",
        "        inter = (gt == u) & (preds==u)\n",
        "        union = (gt == u) | (preds==u)\n",
        "        iou[k] = inter.sum()/union.sum()\n",
        "    return np.round(iou.mean(), 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtPOPrrA11cI",
        "colab_type": "code",
        "outputId": "8d92b60a-1f96-4fb1-fb88-ea74afcda4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# for i in range(image_count):\n",
        "  im = image_batch[1].astype('uint8')\n",
        "  gt = label_batch[1].reshape(sz).astype('int32')\n",
        "\n",
        "  plt.figure(figsize=(14,10))\n",
        "  plt.subplot(141)\n",
        "\n",
        "  plt.imshow(preds1[1])\n",
        "  plt.imshow(image_batch[1].astype('uint8'), alpha=0.0)\n",
        "  # plt.imshow(preds1, alpha=0.5)\n",
        "  plt.title('Original DeepLab\\nmIOU: '+str(mIOU(gt, preds1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Original DeepLab\\nmIOU: 0.3')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANIAAADoCAYAAACaeLqJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBGoBI7SmzP3",
        "colab_type": "text"
      },
      "source": [
        "##Visualize Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmJcB4tSxGVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "fig = plt.figure(figsize=(26,13))\n",
        "gs = gridspec.GridSpec(5, 3, width_ratios=[1, 1, 1],\n",
        "         wspace=0.0, hspace=0.3, top=0.95, bottom=0.05, left=0.17, right=0.845) \n",
        "# f, axarr = plt.subplots(5,3,figsize=(26,13))\n",
        "id =0\n",
        "for i in np.random.choice(100, 5, replace=False):\n",
        "  orig = np.array(Image.fromarray(image_batch[i].astype('uint8')).resize((w, h)))\n",
        "  target = np.array(Image.fromarray(label_batch[i].astype('uint8')).resize((w, h)))\n",
        "  pred = np.array(Image.fromarray(preds1[i].astype('uint8')).resize((w, h)))\n",
        "\n",
        "  ax= plt.subplot(gs[id,0])\n",
        "  ax.imshow(ori)\n",
        "\n",
        "  ax= plt.subplot(gs[id,1])\n",
        "  ax.imshow(target)\n",
        "\n",
        "  ax= plt.subplot(gs[id,2])\n",
        "  ax.imshow(pred)\n",
        "\n",
        "  id = id +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0vfgqgana7y",
        "colab_type": "text"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFsRfiHHne_D",
        "colab_type": "text"
      },
      "source": [
        "1. https://arxiv.org/pdf/1802.02611v3.pdf\n",
        "2. https://github.com/bonlime/keras-deeplab-v3-plus\n",
        "3. https://github.com/Golbstein/Keras-segmentation-deeplab-v3.1\n",
        "4. https://github.com/tensorflow/models/tree/master/research/deeplab\n",
        "5. https://www.analyticsvidhya.com/blog/2019/02/tutorial-semantic-segmentation-google-deeplab/\n",
        "6. https://github.com/amiltonwong/mil-keras-deeplab-v3-plus\n",
        "7. https://github.com/MLearing/Keras-Deeplab-v3-plus\n",
        "8. https://github.com/mjDelta/deeplabv3plus-keras\n",
        "9. https://towardsdatascience.com/review-deeplabv3-atrous-convolution-semantic-segmentation-6d818bfd1d74\n",
        "10. https://www.novatec-gmbh.de/blog/semantic-segmentation-part-1-deeplab-v3/\n",
        "11. https://github.com/jeffery-zhougang/DeeplabV3Plus-Keras-Retraining\n",
        "12. https://github.com/mathildor/DeepLab-v3/blob/master/model.py\n"
      ]
    }
  ]
}